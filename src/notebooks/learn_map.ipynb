{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"/work/ptyagi/masterthesis/data/predictions/feb/averaged_predictions.csv\")\n",
    "annotated = pd.read_csv(\"/work/ptyagi/masterthesis/data/tmp/annotations_and_predictions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(data[['conversation_id', 'tweet_text','roberta-large-predictions','mapped_predictions']],\n",
    "annotated[['manual_label', 'conversation_id', 'replies']], on='conversation_id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>roberta-large-predictions</th>\n",
       "      <th>mapped_predictions</th>\n",
       "      <th>manual_label</th>\n",
       "      <th>replies</th>\n",
       "      <th>vec_11</th>\n",
       "      <th>label_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1096376667117895680</td>\n",
       "      <td>This is the scene in Brighton as a protest ove...</td>\n",
       "      <td>[('anger', 0.728320837020874), ('sadness', 0.3...</td>\n",
       "      <td>[('fear', 0.08991589451929098), ('disgust', 0....</td>\n",
       "      <td>joy</td>\n",
       "      <td>student climate change protest coverage in sha...</td>\n",
       "      <td>[0.1012616, 0.36272985, 0.026058132, 0.0158791...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1096396055678255105</td>\n",
       "      <td>Young people concerned about climate change ga...</td>\n",
       "      <td>[('optimism', 0.9539227485656738), ('anticipat...</td>\n",
       "      <td>[('fear', 0.1304264675767046), ('disgust', 0.0...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>it is everybody s planet but in the last years...</td>\n",
       "      <td>[0.7133801, 0.2396769, 0.95392275, 0.048316047...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1096384227707404288</td>\n",
       "      <td>More crazy Swiss transport socialism. If we ha...</td>\n",
       "      <td>[('optimism', 0.8962536454200745), ('joy', 0.7...</td>\n",
       "      <td>[('fear', 0.007606922902868629), ('disgust', 0...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>on that we are agreed however the question is ...</td>\n",
       "      <td>[0.44626218, 0.030970134, 0.89625365, 0.064893...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1096419453884133376</td>\n",
       "      <td>This gave me so much hope today! Amazing to se...</td>\n",
       "      <td>[('optimism', 0.9923896193504333), ('joy', 0.9...</td>\n",
       "      <td>[('fear', 0.012285791733605866), ('disgust', 0...</td>\n",
       "      <td>anger</td>\n",
       "      <td>cab drivers are just like workers in many othe...</td>\n",
       "      <td>[0.1598584, 0.009998838, 0.9923896, 0.03803576...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1096435275142742016</td>\n",
       "      <td>We're tacking action on #climatechange ðŸŒ³ [URL]</td>\n",
       "      <td>[('optimism', 0.9773759841918945), ('anticipat...</td>\n",
       "      <td>[('fear', 0.04512464413599401), ('disgust', 0....</td>\n",
       "      <td>sadness</td>\n",
       "      <td>this is not good flaring at offshore installat...</td>\n",
       "      <td>[0.42068568, 0.07937623, 0.977376, 0.013604169...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       conversation_id                                         tweet_text  \\\n",
       "0  1096376667117895680  This is the scene in Brighton as a protest ove...   \n",
       "1  1096396055678255105  Young people concerned about climate change ga...   \n",
       "2  1096384227707404288  More crazy Swiss transport socialism. If we ha...   \n",
       "3  1096419453884133376  This gave me so much hope today! Amazing to se...   \n",
       "4  1096435275142742016     We're tacking action on #climatechange ðŸŒ³ [URL]   \n",
       "\n",
       "                           roberta-large-predictions  \\\n",
       "0  [('anger', 0.728320837020874), ('sadness', 0.3...   \n",
       "1  [('optimism', 0.9539227485656738), ('anticipat...   \n",
       "2  [('optimism', 0.8962536454200745), ('joy', 0.7...   \n",
       "3  [('optimism', 0.9923896193504333), ('joy', 0.9...   \n",
       "4  [('optimism', 0.9773759841918945), ('anticipat...   \n",
       "\n",
       "                                  mapped_predictions manual_label  \\\n",
       "0  [('fear', 0.08991589451929098), ('disgust', 0....          joy   \n",
       "1  [('fear', 0.1304264675767046), ('disgust', 0.0...      sadness   \n",
       "2  [('fear', 0.007606922902868629), ('disgust', 0...      sadness   \n",
       "3  [('fear', 0.012285791733605866), ('disgust', 0...        anger   \n",
       "4  [('fear', 0.04512464413599401), ('disgust', 0....      sadness   \n",
       "\n",
       "                                             replies  \\\n",
       "0  student climate change protest coverage in sha...   \n",
       "1  it is everybody s planet but in the last years...   \n",
       "2  on that we are agreed however the question is ...   \n",
       "3  cab drivers are just like workers in many othe...   \n",
       "4  this is not good flaring at offshore installat...   \n",
       "\n",
       "                                              vec_11  label_id  \n",
       "0  [0.1012616, 0.36272985, 0.026058132, 0.0158791...         3  \n",
       "1  [0.7133801, 0.2396769, 0.95392275, 0.048316047...         1  \n",
       "2  [0.44626218, 0.030970134, 0.89625365, 0.064893...         1  \n",
       "3  [0.1598584, 0.009998838, 0.9923896, 0.03803576...         0  \n",
       "4  [0.42068568, 0.07937623, 0.977376, 0.013604169...         1  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     [0.1012616, 0.36272985, 0.026058132, 0.0158791...\n",
      "1     [0.7133801, 0.2396769, 0.95392275, 0.048316047...\n",
      "2     [0.44626218, 0.030970134, 0.89625365, 0.064893...\n",
      "3     [0.1598584, 0.009998838, 0.9923896, 0.03803576...\n",
      "4     [0.42068568, 0.07937623, 0.977376, 0.013604169...\n",
      "                            ...                        \n",
      "94    [0.073052146, 0.15087493, 0.86403126, 0.011630...\n",
      "95    [0.05085175, 0.23804663, 0.02445328, 0.0103589...\n",
      "96    [0.05085175, 0.23804663, 0.02445328, 0.0103589...\n",
      "97    [0.08676346, 0.59624434, 0.02289635, 0.0137726...\n",
      "98    [0.054532796, 0.193984, 0.008681102, 0.1395535...\n",
      "Name: vec_11, Length: 99, dtype: object\n"
     ]
    }
   ],
   "source": [
    "EMOTIONS_11 = [\n",
    "    'anticipation', 'sadness', 'optimism', 'surprise', 'fear',\n",
    "    'disgust', 'joy', 'pessimism', 'anger', 'trust', 'love'\n",
    "]\n",
    "\n",
    "def parse_11_dist(dist_11_tuples):\n",
    "    emotion2prob = dict(ast.literal_eval(dist_11_tuples))\n",
    "    vector = []\n",
    "    for emo in EMOTIONS_11:\n",
    "        vector.append(emotion2prob.get(emo, 0.0))\n",
    "    return np.array(vector, dtype=np.float32)\n",
    "\n",
    "df['vec_11'] = df['roberta-large-predictions'].apply(parse_11_dist)\n",
    "print(df['vec_11'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     3\n",
      "1     1\n",
      "2     1\n",
      "3     0\n",
      "4     1\n",
      "     ..\n",
      "94    1\n",
      "95    0\n",
      "96    2\n",
      "97    4\n",
      "98    5\n",
      "Name: label_id, Length: 99, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "POSSIBLE_6_LABELS = ['anger', 'sadness', 'fear', 'joy', 'disgust', 'surprise']\n",
    "\n",
    "label2id = {label: i for i, label in enumerate(POSSIBLE_6_LABELS)}\n",
    "\n",
    "def encode_label_6(label):\n",
    "    return label2id[label]\n",
    "\n",
    "df['label_id'] = df['manual_label'].apply(encode_label_6)\n",
    "print(df['label_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 79\n",
      "Test size:  20\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Train size:\", len(train_df))\n",
    "print(\"Test size: \", len(test_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class EmotionDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        \n",
    "        # Convert everything into torch tensors once, so we don't do it on-the-fly\n",
    "        self.X = torch.tensor(np.stack(self.df['vec_11'].values), dtype=torch.float32)\n",
    "        self.y = torch.tensor(self.df['label_id'].values, dtype=torch.long)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "train_dataset = EmotionDataset(train_df)\n",
    "test_dataset  = EmotionDataset(test_df)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=2, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class MappingModel(nn.Module):\n",
    "    def __init__(self, in_features=11, out_features=6):\n",
    "        super(MappingModel, self).__init__()\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(in_features, 20),\n",
    "            nn.Linear(20, out_features)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x: (batch_size, 11) input\n",
    "        returns: (batch_size, 6) logits\n",
    "        \"\"\"\n",
    "        return self.mlp(x)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1.8419\n",
      "Epoch 2, Loss: 1.7938\n",
      "Epoch 3, Loss: 1.7617\n",
      "Epoch 4, Loss: 1.7363\n",
      "Epoch 5, Loss: 1.7140\n",
      "Epoch 6, Loss: 1.6999\n",
      "Epoch 7, Loss: 1.6863\n",
      "Epoch 8, Loss: 1.6778\n",
      "Epoch 9, Loss: 1.6675\n",
      "Epoch 10, Loss: 1.6610\n"
     ]
    }
   ],
   "source": [
    "model = MappingModel(in_features=11, out_features=6)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-03)\n",
    "\n",
    "num_epochs = 10 \n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    \n",
    "    for X_batch, y_batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(X_batch)             \n",
    "        loss = criterion(logits, y_batch) \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item() * X_batch.size(0)\n",
    "    \n",
    "    avg_loss = total_loss / len(train_loader.dataset)\n",
    "    print(f\"Epoch {epoch+1}, Loss: {avg_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 45.00%\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for X_batch, y_batch in test_loader:\n",
    "        logits = model(X_batch)               \n",
    "        predictions = torch.argmax(logits, dim=1)  \n",
    "        correct += (predictions == y_batch).sum().item()\n",
    "        total   += y_batch.size(0)\n",
    "\n",
    "accuracy = correct / total if total > 0 else 0.0\n",
    "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted 6-label: anger\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "# Suppose new_dist is a list of (emotion, probability) tuples from your 11-label model\n",
    "new_dist = \"[('anticipation', 0.1), ('sadness', 0.2), ('optimism', 0.2),('surprise', 0.15), ('fear', 0.05), ('disgust', 0.02),('joy', 0.08), ('pessimism', 0.08), ('anger', 0.05),('trust', 0.05), ('love', 0.02)]\"\n",
    "\n",
    "x_vec = parse_11_dist(new_dist)           # shape (11,)\n",
    "x_tensor = torch.tensor(x_vec).unsqueeze(0)  # (1, 11)\n",
    "\n",
    "with torch.no_grad():\n",
    "    logits = model(x_tensor)             # (1, 6)\n",
    "    pred_id = torch.argmax(logits, dim=1).item()  # get integer label\n",
    "    # Map back to the 6-label name\n",
    "    id2label = {v: k for k, v in label2id.items()}\n",
    "    predicted_label = id2label[pred_id]\n",
    "    print(\"Predicted 6-label:\", predicted_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_dist_11 = [0.04657082, 0.01401192, 0.6148004 , 0.04374156, 0.00305552, 0.05579609, 0.997147  , 0.00530904, 0.3977998 , 0.01399408, 0.10514057]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2372, 0.1773, 0.0703, 0.1998, 0.1485, 0.1668]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# 1) Convert your sample distribution to a tensor\n",
    "x_11 = torch.tensor(sample_dist_11, dtype=torch.float32).unsqueeze(0)  \n",
    "# shape: (1, 11)\n",
    "\n",
    "# 2) Forward pass: get raw logits\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    logits_6 = model(x_11)  # shape: (1, 6)\n",
    "\n",
    "# 3) Convert logits to probabilities with softmax\n",
    "prob_dist_6 = F.softmax(logits_6, dim=1)  # shape: (1, 6)\n",
    "\n",
    "# 4) prob_dist_6 is your final 6-emotion distribution \n",
    "print(prob_dist_6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[('fear', 0.003640935125511166), ('disgust', 0.02428697654795146), ('joy', 0.7535070391287398), ('surprise', 0.03931125813234599), ('sadness', 0.006099123162103546), ('anger', 0.173154667903348)]\""
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df[\"mapped_predictions\"].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
