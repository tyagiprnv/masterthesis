\begin{thebibliography}{1}

\bibitem{devlin2019bertpretrainingdeepbidirectional}
Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova.
\newblock Bert: Pre-training of deep bidirectional transformers for language
  understanding, 2019.

\bibitem{dosovitskiy2021imageworth16x16words}
Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn,
  Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg
  Heigold, Sylvain Gelly, Jakob Uszkoreit, and Neil Houlsby.
\newblock An image is worth 16x16 words: Transformers for image recognition at
  scale, 2021.

\bibitem{he2015deepresiduallearningimage}
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
\newblock Deep residual learning for image recognition, 2015.

\bibitem{lewis2019bartdenoisingsequencetosequencepretraining}
Mike Lewis, Yinhan Liu, Naman Goyal, Marjan Ghazvininejad, Abdelrahman Mohamed,
  Omer Levy, Ves Stoyanov, and Luke Zettlemoyer.
\newblock Bart: Denoising sequence-to-sequence pre-training for natural
  language generation, translation, and comprehension, 2019.

\bibitem{prasse2023towards}
Katharina Prasse, Steffen Jung, Isaac~B Bravo, Stefanie Walter, and Margret
  Keuper.
\newblock Towards understanding climate change perceptions: A social media
  dataset.
\newblock In {\em NeurIPS 2023 Workshop on Tackling Climate Change with Machine
  Learning}, 2023.

\bibitem{radford2021learningtransferablevisualmodels}
Alec Radford, Jong~Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh,
  Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark,
  Gretchen Krueger, and Ilya Sutskever.
\newblock Learning transferable visual models from natural language
  supervision, 2021.

\bibitem{tan2020efficientnetrethinkingmodelscaling}
Mingxing Tan and Quoc~V. Le.
\newblock Efficientnet: Rethinking model scaling for convolutional neural
  networks, 2020.

\bibitem{Yang_2023_ICCV}
Jingyuan Yang, Qirui Huang, Tingting Ding, Dani Lischinski, Danny Cohen-Or, and
  Hui Huang.
\newblock Emoset: A large-scale visual emotion dataset with rich attributes.
\newblock In {\em Proceedings of the IEEE/CVF International Conference on
  Computer Vision (ICCV)}, pages 20383--20394, October 2023.

\bibitem{yin2019benchmarkingzeroshottextclassification}
Wenpeng Yin, Jamaal Hay, and Dan Roth.
\newblock Benchmarking zero-shot text classification: Datasets, evaluation and
  entailment approach, 2019.

\end{thebibliography}
